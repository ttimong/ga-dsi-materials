{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Practicing Web Scraping with XPath\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Practice scraping basics\n",
    "- Review HTML and XPath basics\n",
    "- Practice scraping a website for various data and put this into a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Review of HTML and web scraping](#review1)\n",
    "- [Review of XPath](#review2)\n",
    "- [Basic XPath expressions](#basic-xpath)\n",
    "    - [Absolute references](#absolute)\n",
    "    - [Relative references](#relative-references)\n",
    "    - [Selecting attributes](#attributes)\n",
    "- [Guided practice: Where's Waldo - \"XPath Edition\"](#practice1)\n",
    "- [1 vs. N selections](#1vsn)\n",
    "    - [Selecting the first element in a series of elements](#first-elem)\n",
    "    - [Selecting the last element in a series of elements](#last-elem)\n",
    "    - [Selecting all elements matching a selection](#all-elem-match)\n",
    "    - [Selecting elements matching an attribute](#elem-match-attr)\n",
    "- [Guided practice: selecting elements](#practice2)\n",
    "- [A quick note: the requests module](#requests)\n",
    "- [Guided practice: scrape Data Tau headlines](#practice3)\n",
    "- [Independent practice](#independent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review1'></a>\n",
    "## Review of HTML and web scraping\n",
    "\n",
    "---\n",
    "\n",
    "Web scraping is a technique of extracting information from websites. It is the download and transformation of unstructured data on the web into structured data that can be stored and analyzed.\n",
    "\n",
    "There are a variety of ways to \"scrape\" what we want from the web:\n",
    "- 3rd Party Services (import.io)\n",
    "- Write our own Python apps that pull HTML documents and parse them\n",
    "  - Mechanize\n",
    "  - Scrapy\n",
    "  - Requests\n",
    "  - libxml / XPath\n",
    "  - Regular expressions\n",
    "  - BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Check:** What do you perceive to be the hardest aspect of scraping?\n",
    "\n",
    "_ie: If you were asked to scrape craigslist property listings and put them in a DataFrame(), what would hold you up?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: HTML\n",
    "\n",
    "In the HTML DOM (Document Object Model), everything is a node:\n",
    " * The document itself is a document node.\n",
    " * All HTML elements are element nodes.\n",
    " * All HTML attributes are attribute nodes.\n",
    " * Text inside HTML elements are text nodes.\n",
    " * Comments are comment nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: elements\n",
    "Elements begin and end with **open and close \"tags\"**, which are defined by namespaced, encapsulated strings. \n",
    "\n",
    "```html\n",
    "<title>I am a title.</title>\n",
    "<p>I am a paragraph.</p>\n",
    "<strong>I am bold.</strong>\n",
    "```\n",
    "\n",
    "_note: the tags **title, p,** and **strong** are represented below._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: element parent / child relationships\n",
    "\n",
    "<img src=\"http://www.htmlgoodies.com/img/2007/06/flowChart2.gif\" width=\"250\">\n",
    "\n",
    "**Elements begin and end in the same namespace like so:**  `<p></p>`\n",
    "\n",
    "**Elements can have parents and children:** It is important to remember that an element can be both a parent and a child and whether to refer to the element as a parent or a child depends on the specific element you are referencing relative to it.\n",
    "\n",
    "_Your parents are **parents** to you but **children** of your grandparents.  Same logic applies with html elements._\n",
    "\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the child of 'parent'\n",
    "        <div id = 'child_2'>I am the child of 'child_1'\n",
    "            <div id = 'child_3'>I am the child of 'child_2'\n",
    "                <div id = 'child_4'>I am the child of 'child_4'</div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```\n",
    "\n",
    "**or**\n",
    "\n",
    "```html\n",
    "<body id = 'parent'>\n",
    "    <div id = 'child_1'>I am the parent of 'child_2'\n",
    "        <div id = 'child_2'>I am the parent of 'child_3'\n",
    "            <div id = 'child_3'> I am the parent of 'child_4'\n",
    "                <div id = 'child_4'>I am not a parent </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "</body>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review: element attributes\n",
    "\n",
    "Elements can also have attributes!  Attributes are defined inside **element tags** and can contain data that may be useful to scrape.\n",
    "\n",
    "```html\n",
    "<a href=\"http://lmgtfy.com/?q=html+element+attributes\" title=\"A title\" id=\"web-link\" name=\"hal\">A Simple Link</a>\n",
    "```\n",
    "\n",
    "The **element attributes** of this `<a>` tag element are:\n",
    "- `id`\n",
    "- `href`\n",
    "- `title`\n",
    "- `name`\n",
    "\n",
    "This `<a>` tag example will render in your browser like this:\n",
    "> <a href=\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\">A Simple Link</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** Can you identify an attribute, an element, a text item, and a child element?\n",
    "\n",
    "```HTML\n",
    "<html>\n",
    "   <title id=\"main-title\">All this scraping is making me itch!</title>\n",
    "   <body>\n",
    "       <h1>Welcome to my Homepage</h1>\n",
    "       <p id=\"welcome-paragraph\" class=\"strong-paragraph\">\n",
    "           <span>Hello friends, let me tell you about this cool hair product..</span>\n",
    "           <ul>\n",
    "              <li>It's cool</li>\n",
    "              <li>It's fresh</li>\n",
    "              <li>It can tell the future</li>\n",
    "              <li>Always be closing</li>\n",
    "           </ul>\n",
    "       </p>\n",
    "   </body>\n",
    "```\n",
    "\n",
    "**Bonus: What's missing?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# </html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='review2'></a>\n",
    "## Review of XPath\n",
    "\n",
    "---\n",
    "\n",
    "XPath uses path expressions to select nodes or node-sets in an HTML/XML document. These path expressions look very much like the expressions you see when you work with a traditional computer file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath features\n",
    "\n",
    "XPath includes over 100 built-in functions to help us select and manipulate HTML (or XML) documents. XPath has functions for:\n",
    "\n",
    "- string values\n",
    "- numeric values\n",
    "- date and time comparison\n",
    "- sequence manipulation\n",
    "- Boolean values\n",
    "- and more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic-xpath'></a>\n",
    "## Basic XPath expressions\n",
    "\n",
    "---\n",
    "\n",
    "XPath comes with a wide array of features but the basics of selecting data are the most common problems that XPath can help you solve.\n",
    "\n",
    "The most common task you'll use **XPath** for is selecting data from HTML documents.  There are two ways you can **select elements** within HTML using **XPath**:\n",
    "\n",
    "- Absolute reference\n",
    "- Relative reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='absolute'></a>\n",
    "### Absolute references\n",
    "\n",
    "> _For our XPath demonstration, we will use Scrapy, which is using [libxml](http://xmlsoft.org) under the hood.  Libxml provides the basic functionality for XPath expressions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install scrapy\n",
    "# pip install --upgrade zope2\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "\n",
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        <span id=\"only-span\">good</span>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "# The same thing but \"absolute\" reference\n",
    "Selector(text=HTML).xpath('/html/body/span/text()').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='relative-references'></a>\n",
    "### Relative references\n",
    "\n",
    "Relative references in XPath match the \"ends\" of structures.  Since there is only a single \"span\" element, `//span/text()` matches **one element**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'good']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='attributes'></a>\n",
    "### Selecting attributes\n",
    "\n",
    "Attributes **within a tag**, such as `id=\"only-span\"` within our span attribute.  We can get the attribute by using `@` symbol **after** the **element reference**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'only-span']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span/@id').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice1'></a>\n",
    "## Guided practice: Where's Waldo - \"XPath Edition\"\n",
    "\n",
    "---\n",
    "\n",
    "**In this example, we will find Waldo together.  Find Waldo as an:**\n",
    "\n",
    "- Element\n",
    "- Attribute\n",
    "- Text element\n",
    "\n",
    "The practice HTML string is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "        \n",
    "        <ul id=\"waldo\">\n",
    "            <li class=\"waldo\">\n",
    "                <span> yo Im not here</span>\n",
    "            </li>\n",
    "            <li class=\"waldo\">Height:  ???</li>\n",
    "            <li class=\"waldo\">Weight:  ???</li>\n",
    "            <li class=\"waldo\">Last Location:  ???</li>\n",
    "            <li class=\"nerds\">\n",
    "                <div class=\"alpha\">Bill gates</div>\n",
    "                <div class=\"alpha\">Zuckerberg</div>\n",
    "                <div class=\"beta\">Theil</div>\n",
    "                <div class=\"animal\">parker</div>\n",
    "            </li>\n",
    "        </ul>\n",
    "        \n",
    "        <ul id=\"tim\">\n",
    "            <li class=\"tdawg\">\n",
    "                <span>yo im here</span>\n",
    "            </li>\n",
    "        </ul>\n",
    "        <li>stuff</li>\n",
    "        <li>stuff2</li>\n",
    "        \n",
    "        <div id=\"cooldiv\">\n",
    "            <span class=\"dsi-rocks\">\n",
    "               YO!\n",
    "            </span>\n",
    "        </div>\n",
    "        \n",
    "        \n",
    "        <waldo>Waldo</waldo>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'waldo',\n",
       " u'nerds',\n",
       " u'alpha',\n",
       " u'alpha',\n",
       " u'beta',\n",
       " u'animal',\n",
       " u'tdawg',\n",
       " u'dsi-rocks']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//@class').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Waldo']\n",
      "[u'\\n                ', u'\\n            ', u'Height:  ???', u'Weight:  ???', u'Last Location:  ???', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n                ', u'\\n            ', u'\\n                ', u'\\n            ']\n",
      "[u'<li class=\"waldo\">\\n                <span> yo Im not here</span>\\n            </li>', u'<li class=\"waldo\">Height:  ???</li>', u'<li class=\"waldo\">Weight:  ???</li>', u'<li class=\"waldo\">Last Location:  ???</li>', u'<li class=\"nerds\">\\n                <div class=\"alpha\">Bill gates</div>\\n                <div class=\"alpha\">Zuckerberg</div>\\n                <div class=\"beta\">Theil</div>\\n                <div class=\"animal\">parker</div>\\n            </li>', u'<li class=\"tdawg\">\\n                <span>yo im here</span>\\n            </li>', u'<li>stuff</li>', u'<li>stuff2</li>']\n",
      "[u'waldo', u'waldo', u'waldo', u'waldo', u'nerds', u'alpha', u'alpha', u'beta', u'animal', u'tdawg', u'dsi-rocks']\n",
      "[u'waldo', u'tim']\n"
     ]
    }
   ],
   "source": [
    "# Find absolute element\n",
    "print Selector(text=HTML).xpath('/html/body/waldo/text()').extract()\n",
    "print Selector(text=HTML).xpath('/html/body/ul/li/text()').extract()\n",
    "\n",
    "# Find relative element\n",
    "print Selector(text=HTML).xpath('//li').extract()\n",
    "\n",
    "# Find element attribute\n",
    "print Selector(text=HTML).xpath('////@class').extract()\n",
    "print Selector(text=HTML).xpath('//ul/@id').extract()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1vsn'></a>\n",
    "## 1 vs N selections\n",
    "\n",
    "---\n",
    "\n",
    "When selecting elements via relative reference, it's possible that you will select multiple items.  It's still possible to select single items, if you're specfic enough.\n",
    "\n",
    "**Singular Reference**\n",
    "- **Index** starts at **1**\n",
    "- Selections by offset\n",
    "- Selections by \"first\" or \"last\"\n",
    "- Selections by **unique attribute value**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML = \"\"\"\n",
    "<html>\n",
    "    <body>\n",
    "    \n",
    "        <!-- Search Results -->\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=751hUX_q0Do\" title=\"Rappin with Gas\">Rapping with gas</a>\n",
    "           <span class=\"link-details\">This is a great video about gas.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=97byWqi-zsI\" title=\"Casio Rapmap\">The Rapmaster</a>\n",
    "           <span class=\"link-details\">My first synth ever.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=TSwqnR327fk\" title=\"Cinco Products\">Cinco Midi Organizer</a>\n",
    "           <span class=\"link-details\">Midi files at the speed of light.</span>\n",
    "        </div>\n",
    "        <div class=\"search-result\">\n",
    "           <a href=\"https://www.youtube.com/watch?v=8TCxE0bWQeQ\" title=\"Baddest Gates\">BBG Baddest Moments</a>\n",
    "           <span class=\"link-details\">It's tough to be a gangster.</span>\n",
    "        </div>\n",
    "        \n",
    "        <!-- Page stats -->\n",
    "        <div class=\"page-stats-container\">\n",
    "            <li class=\"item\" id=\"pageviews\">1,333,443</li>\n",
    "            <li class=\"item\" id=\"somethingelse\">bla</li>\n",
    "            <li class=\"item\" id=\"last-viewed\">01-22-2016</li>\n",
    "            <li class=\"item\" id=\"views-per-hour\">1,532</li>\n",
    "            <li class=\"item\" id=\"kiefer-views-per-hour\">5,233.42</li>\n",
    "        </div>\n",
    "        \n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "span = Selector(text=HTML).xpath('/html/body/div/li[@id=\"kiefer-views-per-hour\"]/text()').extract()\n",
    "span"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first-elem'></a>\n",
    "### Selecting the first element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">This is a great video about gas.</span>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='last-elem'></a>\n",
    "### Selecting the last element in a series of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans = Selector(text=HTML).xpath('//span').extract()\n",
    "spans[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='all-elem-match'></a>\n",
    "### Selecting all elements matching a selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'<span class=\"link-details\">This is a great video about gas.</span>',\n",
       " u'<span class=\"link-details\">My first synth ever.</span>',\n",
       " u'<span class=\"link-details\">Midi files at the speed of light.</span>',\n",
       " u'<span class=\"link-details\">It\\'s tough to be a gangster.</span>']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text=HTML).xpath('//span').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='elem-match-attr'></a>\n",
    "### Selecting elements matching an _attribute_\n",
    "\n",
    "This will be one of the most common ways you will select items.  HTML DOM elements will be more differentiated based on their \"class\" and \"id\" variables.  Mainly, these types of attributes are used by web developers to refer to specfic elements or a broad set of elements to apply visual characteristics using CSS.\n",
    "\n",
    "```HTML \n",
    "//element[@attribute=\"value\"]\n",
    "```\n",
    "\n",
    "**Generally**\n",
    "\n",
    "- \"class\" attributes within elements usually refer to multiple items.\n",
    "- \"id\" attributes are supposed to be unique, but not always.\n",
    "\n",
    "_CSS stands for cascading style sheets.  These are used to abstract the definition of visual elements on a micro and macro scale for the web.  They are also our best friend as data miners.  They give us strong hints and cues as to how a web document is structured._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice2'></a>\n",
    "## Guided practice: selecting elements\n",
    "\n",
    "---\n",
    "\n",
    "1. **How can we get a series of only text items for the page statistics section of our page?**\n",
    "2. **We want to know only how many times Kiefer views my Youtube videos page per hour?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//li/text()' data=u'1,333,443'>,\n",
       " <Selector xpath='//li/text()' data=u'bla'>,\n",
       " <Selector xpath='//li/text()' data=u'01-22-2016'>,\n",
       " <Selector xpath='//li/text()' data=u'1,532'>,\n",
       " <Selector xpath='//li/text()' data=u'5,233.42'>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all text elements for the page statistics section\n",
    "Selector(text=HTML).xpath('//li/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'5,233.42']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "# Selector(text=HTML).xpath('//div[@class=\"page-stats-container\"]/li[4]/text()').extract()\n",
    "\n",
    "# Get only the text for \"Kiefer's\" number of views per hour\n",
    "Selector(text=HTML).xpath('//li[@id=\"kiefer-views-per-hour\"]/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "## A quick note:  the `requests` module\n",
    "\n",
    "---\n",
    "\n",
    "The requests module is the gateway to interacting with the web using Python.  We can:\n",
    "\n",
    " - Fetch web documents as strings\n",
    " - Decode JSON\n",
    " - Basic data munging with Web Documents\n",
    " - Download static files that are not text\n",
    "  - Images\n",
    "  - Videos\n",
    "  - Binary data\n",
    "\n",
    "\n",
    "Take some time and read up on Requests:\n",
    "\n",
    "http://docs.python-requests.org/en/master/user/quickstart/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='practice3'></a>\n",
    "## Guided practice: scrape Data Tau headlines\n",
    "\n",
    "DataTau is a great site for data science news. Let's take their headlines using Python **`requests`**, and practice selecting various elements.\n",
    "\n",
    "Using <a href=\"https://chrome.google.com/webstore/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=en\">XPath helper Chrome plugin</a> _(cmd-shift-x)_ and the Chrome \"inspect\" feature, let's explore the structure of the page.\n",
    "\n",
    "_Here's a <a href=\"https://www.youtube.com/watch?v=i2Li1vnv09U\">concise video</a> that demonstrates the basic inspect feature within Chrome._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<html><head><link rel=\"stylesheet\" type=\"text/css\" href=\"news.css\">\\n<link rel=\"shortcut icon\" href=\"http://www.iconj.com/ico/d/x/dxo02ap56v.ico\">\\n<scr'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please only run this frame once to avoid hitting the site too hard all at once\n",
    "import requests\n",
    "\n",
    "response = requests.get(\"http://www.datatau.com\")\n",
    "HTML = response.text  \n",
    "HTML[0:150]           # view the first 500 characters of the HTML index document for DataTau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Only The Headlines\n",
    "\n",
    "We will use the XPath helper tool to inspect the markup that comprises the **title** to find any pattern.  Since there are more than one **titles**, we expect to find a series of elements representing the **title** data that we are interested in.\n",
    "\n",
    "In this example, we are referencing the the **1st center**, **3rd table row (`tr[3]`)**, within the 2nd **td having a class of \"title\" (`td[@class=\"title\"][2]`)**, and the anchor tag within a **(`a/text()`)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'New York City: Data Science\\u2019s Best Bet for Growth and Opportunity',\n",
       " u\"You can't come up with one woman?\",\n",
       " u'Using NLP to find familiar meals at new restaurants',\n",
       " u'Interactive Visualizations In Jupyter Notebook',\n",
       " u'Bayesian learning for statistical classification to improve your model',\n",
       " u'Self Driving Cab Simulator',\n",
       " u'TED Talks Dataset',\n",
       " u'When Are Citi Bikes Faster Than Taxis in New York City?',\n",
       " u'End-to-end machine learning on the GPU with GOAI',\n",
       " u'The Ten Fallacies of Data Science Work']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "titles = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/text()').extract()\n",
    "titles[0:10] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we get the urls from the titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=de7nLfGLCd',\n",
       " u'https://techcrunch.com/2017/06/16/object-detection-api/',\n",
       " u'https://arxiv.org/abs/1705.10883',\n",
       " u'http://blog.ethanrosenthal.com/2017/06/20/matrix-factorization-in-pytorch/',\n",
       " u'https://elitedatascience.com/bias-variance-tradeoff',\n",
       " u'https://techcrunch.com/2017/06/14/element-ai-a-platform-for-companies-to-build-ai-solutions-raises-102m/',\n",
       " u'https://github.com/indrajithi/mgc-django',\n",
       " u'https://arogozhnikov.github.io/3d_nn/',\n",
       " u'https://devblogs.nvidia.com/parallelforall/goai-open-gpu-accelerated-data-analytics/',\n",
       " u'https://data36.com/optimize-facebook-campaigns/',\n",
       " u'http://willwolf.io/2017/06/15/random-effects-neural-networks/',\n",
       " u'http://willwolf.io/2017/06/19/neurally-embedded-emojis/',\n",
       " u'https://medium.com/xtrememl/why-how-to-use-windows-10-wsl-built-in-linux-for-machine-learning-6a225f4bbd3a',\n",
       " u'https://www.mapd.com/blog/2017/06/18/release-feature-focus-being-smart-not-dense-with-immerse-density-gradients/',\n",
       " u'https://www.dataandsons.com/',\n",
       " u'https://www.ayasdi.com/blog/artificial-intelligence/envisioning-future-intelligent-applications/',\n",
       " u'http://novusviatech.com/2017/03/14/1605/',\n",
       " u'https://blog.godatadriven.com/reverse-engineering-boardgamegeek',\n",
       " u'http://datawanderings.com/2017/06/16/ko-by-probability/',\n",
       " u'https://scribie.com/blog/2017/06/building-custom-deep-learning-rig/',\n",
       " u'https://blog.statsbot.co/open-source-business-intelligence-523ba185d530',\n",
       " u'https://www.oreilly.com/learning/probabilistic-programming-from-scratch',\n",
       " u'https://monkeylearn.com/blog/introduction-to-support-vector-machines-svm/',\n",
       " u'http://byteacademy.co/blog/data-science-podcasts',\n",
       " u'https://blog.insightdatascience.com/pitcher-prognosis-using-machine-learning-to-predict-baseball-injuries-7f49b36f88e6',\n",
       " u'https://kndrck.co/indexing-faces-on-instagram.html',\n",
       " u'https://plot.ly/products/dash/',\n",
       " u'https://blog.statsbot.co/data-scientist-resume-projects-806a74388ae6',\n",
       " u'https://blog.insightdatascience.com/using-deep-learning-to-reconstruct-high-resolution-audio-29deee8b7ccd',\n",
       " u'https://elitedatascience.com/beginner-mistakes',\n",
       " u'https://blog.insightdatascience.com/the-data-engineering-ecosystem-in-2017-2c2a3429350e']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = Selector(text=HTML).xpath('//td[@class=\"title\"]/a/@href').extract()\n",
    "urls[::-1]\n",
    "#<a href=\"http://tech.marksblogg.com/faster-queries-google-cloud-dataproc.html\">33x Faster Queries on Google Cloud's Dataproc using Facebook's Presto</a>\n",
    "# titles[0:5] # the first 5 titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we get the site domain, after the title within the parentheses (ie: stitchfix.com)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "domains = Selector(text=HTML).xpath(\"//span[@class='comhead']/text()\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u' (insightdatascience.com) ',\n",
       " u' (elitedatascience.com) ',\n",
       " u' (insightdatascience.com) ',\n",
       " u' (statsbot.co) ',\n",
       " u' (plot.ly) ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about the points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'3 points', u'13 points', u'7 points', u'9 points', u'7 points']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = Selector(text=HTML).xpath('//td[@class=\"subtext\"]/span/text()').extract()\n",
    "points[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about the \"more Link?\"\n",
    "\n",
    "> *Hint:  You can use `element[text()='exact text']` to find text element matching specific text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/x?fnid=de7nLfGLCd']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_link = Selector(text=HTML).xpath('//a[text()=\"More\"]/@href').extract()\n",
    "next_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='independent'></a>\n",
    "## Independent practice\n",
    "\n",
    "---\n",
    "\n",
    "**For the next 30 minutes try to grab the following from Data Tau:**\n",
    "\n",
    "- Story titles\n",
    "- Story URL (href)\n",
    "- Domain\n",
    "- Points\n",
    "\n",
    "**Stretch goals:**\n",
    "- Author\n",
    "- Comment count\n",
    "\n",
    "**Put your results into a DataFrame.**\n",
    "\n",
    "- Do basic analysis of domains and point distributions\n",
    "\n",
    "**BONUS:**\n",
    "\n",
    "Automatically find the next \"more link\" and mine the next page(s) until none exist.  Logically, you can each page with this pseudo code:\n",
    "\n",
    "1. Does the next link exist (a tag with text == \"More\")\n",
    "- Fetch URL, prepended with domain (datatau.com/(extracted link here))\n",
    "- Parse the page with `Selector(text=HTML).xpath('').extract()` to find the elements\n",
    "- Add to dataframe\n",
    "\n",
    "> _Note:  You might want to set a limit something like 2-3 total requests per attempt to avoid unecessary transfer._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching http://www.datatau.com/x?fnid=ISDTQ2p1bz...\n",
      "Fetching http://www.datatau.com/x?fnid=KrI45lZv0A...\n",
      "Fetching http://www.datatau.com/x?fnid=YTa77kRVQb...\n",
      "Fetching http://www.datatau.com/x?fnid=GGH6o5b58c...\n",
      "Fetching http://www.datatau.com/x?fnid=up00dadwoR...\n",
      "Fetching http://www.datatau.com/x?fnid=3WLrlmSA40...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>authors</th>\n",
       "      <th>comments</th>\n",
       "      <th>domains</th>\n",
       "      <th>links</th>\n",
       "      <th>points</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>meghido</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(roialty.com)</td>\n",
       "      <td>http://roialty.com/why-are-clusters-important-...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Clustering Social Media Audience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>kokorcsin</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://data36.com/sql-for-data-analysis-tutor...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>SQL for Data Analysis – Tutorial for Beginners...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lmcinnes</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://lmcinnes.github.io/subreddit_mapping/</td>\n",
       "      <td>12 points</td>\n",
       "      <td>Mapping and Analysing SubReddits Using Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>freebiesmall</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(freebiesmall.com)</td>\n",
       "      <td>https://www.freebiesmall.com/blog/best-helveti...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Top 5 Fonts That Can Take The Place of Helveti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>freebiesmall</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(freebiesmall.com)</td>\n",
       "      <td>https://www.freebiesmall.com/blog/call-to-acti...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Call to Action Button Examples Every UI/UX Des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>axelr</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>http://arogozhnikov.github.io/2017/04/20/machi...</td>\n",
       "      <td>14 points</td>\n",
       "      <td>Machine Learning in Science and Industry [slides]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>deeplearningt</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(deeplearningtrack.com)</td>\n",
       "      <td>https://www.deeplearningtrack.com/single-post/...</td>\n",
       "      <td>20 points</td>\n",
       "      <td>Learn under the hood of Gradient Descent algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Alphax</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(tjpalanca.com)</td>\n",
       "      <td>http://www.tjpalanca.com/2017/03/facebook-news...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Using topic modeling to find trends in Faceboo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>marklit</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(marksblogg.com)</td>\n",
       "      <td>http://tech.marksblogg.com/billion-nyc-taxi-ri...</td>\n",
       "      <td>8 points</td>\n",
       "      <td>1.1 Billion Taxi Rides with MapD 3.0 &amp; 2 GPU-P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>saloni_S</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(byteacademy.co)</td>\n",
       "      <td>http://byteacademy.co/blog/beginner-deep-learn...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>A Beginner's Guide to Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>cavaunpeu</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(willwolf.io)</td>\n",
       "      <td>http://willwolf.io/2017/05/08/transfer-learnin...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Transfer Learning for Flight Delay Prediction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Weenkus</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datawhatnow.com)</td>\n",
       "      <td>https://datawhatnow.com/simhash-question-dedup...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>SimHash for question deduplication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>ibobriakov</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(linkedin.com)</td>\n",
       "      <td>item?id=17958</td>\n",
       "      <td>19 points</td>\n",
       "      <td>Ask DT: What is the best hardware/GPU for deep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>highraja</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>https://www.linkedin.com/pulse/applying-face-r...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Applying Microsoft Cognitive Emotion Recogniti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(sp-bx.com)</td>\n",
       "      <td>http://blog.paralleldots.com/data-scientist/7-...</td>\n",
       "      <td>15 points</td>\n",
       "      <td>7 types of job profiles that make you a Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Soapbox</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://www.sp-bx.com/getting-grips-blockchain/</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Getting to grips with Blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>kokorcsin</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>https://data36.com/learn-data-analytics-bash-s...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>7 articles to learn basics of Command Line/Bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(jupyter.org)</td>\n",
       "      <td>http://blog.paralleldots.com/technology/machin...</td>\n",
       "      <td>18 points</td>\n",
       "      <td>Some Lesser Known Machine Learning Libraries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>sqadri</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>http://blog.jupyter.org/2017/04/04/jupyter-not...</td>\n",
       "      <td>20 points</td>\n",
       "      <td>Jupyter Notebook 5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(blogspot.com.ar)</td>\n",
       "      <td>http://blog.paralleldots.com/technology/machin...</td>\n",
       "      <td>20 points</td>\n",
       "      <td>List of Free Must-Read Books for Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>enmanuel</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(freebiesmall.com)</td>\n",
       "      <td>http://python-apuntes.blogspot.com.ar/2017/04/...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Python script for create dummies (using \"featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>digambersingh89</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(jonathansacramento.com)</td>\n",
       "      <td>https://www.freebiesmall.com/blog/not-to-miss-...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Not To Miss YouTube Channels For Designers And...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>jmsmistral</td>\n",
       "      <td>3 comments</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>http://jonathansacramento.com/posts/20170416_c...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Predicting Churn without Machine Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datawhatnow.com)</td>\n",
       "      <td>http://blog.paralleldots.com/technology/deep-l...</td>\n",
       "      <td>11 points</td>\n",
       "      <td>Some Lesser-Known Deep Learning Libraries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>Weenkus</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(okcupid.com)</td>\n",
       "      <td>http://datawhatnow.com/feature-importance/</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Feature importance and why it's important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>okcdata</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(chris-said.io)</td>\n",
       "      <td>https://tech.okcupid.com/the-pitfalls-of-a-b-t...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>The pitfalls of A/B testing in social networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>csaid81</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>http://chris-said.io/2017/05/03/empirical-baye...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Empirical Bayes for multiple sample sizes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>mwakanosya</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(paralleldots.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/separating...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Separating Overlapping Chromosomes with Deep L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>gargisharma</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(autodeskresearch.com)</td>\n",
       "      <td>http://blog.paralleldots.com/technology/deep-l...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Emotion Detection Using Machine Learning - Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>Bassviola</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.autodeskresearch.com/publications/...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Same Stats, Different Graphs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0</td>\n",
       "      <td>e_ameisen</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/the-data-e...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>The data engineering ecosystem in 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1</td>\n",
       "      <td>lizeds</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(elitedatascience.com)</td>\n",
       "      <td>https://elitedatascience.com/beginner-mistakes</td>\n",
       "      <td>13 points</td>\n",
       "      <td>9 Mistakes to Avoid When Starting Your Career ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2</td>\n",
       "      <td>e_ameisen</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/using-deep...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Using Deep Learning to Reconstruct High-Resolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3</td>\n",
       "      <td>kate</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(statsbot.co)</td>\n",
       "      <td>https://blog.statsbot.co/data-scientist-resume...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Data Scientist Resume Projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>asiaticchamoir</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(plot.ly)</td>\n",
       "      <td>https://plot.ly/products/dash/</td>\n",
       "      <td>7 points</td>\n",
       "      <td>Dash by Plotly - Build beautiful web-based int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5</td>\n",
       "      <td>pvl</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(kndrck.co)</td>\n",
       "      <td>https://kndrck.co/indexing-faces-on-instagram....</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Indexing Faces on Instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>6</td>\n",
       "      <td>ivan_zheng</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(insightdatascience.com)</td>\n",
       "      <td>https://blog.insightdatascience.com/pitcher-pr...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Pitcher Prognosis: Using Machine Learning to P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>7</td>\n",
       "      <td>saloni_S</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(byteacademy.co)</td>\n",
       "      <td>http://byteacademy.co/blog/data-science-podcasts</td>\n",
       "      <td>8 points</td>\n",
       "      <td>Great list of podcasts if you are interested i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>8</td>\n",
       "      <td>feconroses</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(monkeylearn.com)</td>\n",
       "      <td>https://monkeylearn.com/blog/introduction-to-s...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>An introduction to Support Vector Machines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>9</td>\n",
       "      <td>mikepqr</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(oreilly.com)</td>\n",
       "      <td>https://www.oreilly.com/learning/probabilistic...</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Probabilistic programming from scratch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10</td>\n",
       "      <td>belokon</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(statsbot.co)</td>\n",
       "      <td>https://blog.statsbot.co/open-source-business-...</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Open source business intelligence tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11</td>\n",
       "      <td>ashwath</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(scribie.com)</td>\n",
       "      <td>https://scribie.com/blog/2017/06/building-cust...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Building a Custom Deep Learning Rig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>12</td>\n",
       "      <td>datactopus</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(datawanderings.com)</td>\n",
       "      <td>http://datawanderings.com/2017/06/16/ko-by-pro...</td>\n",
       "      <td>4 points</td>\n",
       "      <td>Taking Down the NPS Score: KO by Probability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>13</td>\n",
       "      <td>jhoek</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(godatadriven.com)</td>\n",
       "      <td>https://blog.godatadriven.com/reverse-engineer...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>ReveRse engineering BoardGameGeek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>14</td>\n",
       "      <td>HRtechtoday</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(novusviatech.com)</td>\n",
       "      <td>http://novusviatech.com/2017/03/14/1605/</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Improve the Application Process for Candidates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>15</td>\n",
       "      <td>carolk</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(ayasdi.com)</td>\n",
       "      <td>https://www.ayasdi.com/blog/artificial-intelli...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Envisioning the Future of Intelligent Applicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>16</td>\n",
       "      <td>dataandsons</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(dataandsons.com)</td>\n",
       "      <td>https://www.dataandsons.com/</td>\n",
       "      <td>3 points</td>\n",
       "      <td>New Data Exchange for Buying, Selling, and Sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>17</td>\n",
       "      <td>tmostak</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(mapd.com)</td>\n",
       "      <td>https://www.mapd.com/blog/2017/06/18/release-f...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Density Gradient Maps and Scatterplots in MapD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>18</td>\n",
       "      <td>rootkit</td>\n",
       "      <td>1 comment</td>\n",
       "      <td>(medium.com)</td>\n",
       "      <td>https://medium.com/xtrememl/why-how-to-use-win...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Why\\How to use Windows Linux Subsytem for end ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>19</td>\n",
       "      <td>cavaunpeu</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(willwolf.io)</td>\n",
       "      <td>http://willwolf.io/2017/06/19/neurally-embedde...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Neurally Embedded Emojis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>20</td>\n",
       "      <td>cavaunpeu</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(willwolf.io)</td>\n",
       "      <td>http://willwolf.io/2017/06/15/random-effects-n...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Random Effects Neural Networks in Edward and K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>21</td>\n",
       "      <td>kokorcsin</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(data36.com)</td>\n",
       "      <td>https://data36.com/optimize-facebook-campaigns/</td>\n",
       "      <td>2 points</td>\n",
       "      <td>How to Optimize Facebook Campaigns Based on Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>22</td>\n",
       "      <td>ethikal</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(nvidia.com)</td>\n",
       "      <td>https://devblogs.nvidia.com/parallelforall/goa...</td>\n",
       "      <td>7 points</td>\n",
       "      <td>GOAI: Open GPU-Accelerated Data Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>23</td>\n",
       "      <td>axelr</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.io)</td>\n",
       "      <td>https://arogozhnikov.github.io/3d_nn/</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Visualizing neural networks in 3d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>24</td>\n",
       "      <td>carlosgg</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(github.com)</td>\n",
       "      <td>https://github.com/indrajithi/mgc-django</td>\n",
       "      <td>5 points</td>\n",
       "      <td>Music Genre Classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>25</td>\n",
       "      <td>sameermanek</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(techcrunch.com)</td>\n",
       "      <td>https://techcrunch.com/2017/06/14/element-ai-a...</td>\n",
       "      <td>6 points</td>\n",
       "      <td>Element AI raises $102M for AI Incubator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>26</td>\n",
       "      <td>lizeds</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(elitedatascience.com)</td>\n",
       "      <td>https://elitedatascience.com/bias-variance-tra...</td>\n",
       "      <td>17 points</td>\n",
       "      <td>WTF is the Bias-Variance Tradeoff? (Infographic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>27</td>\n",
       "      <td>thang</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(ethanrosenthal.com)</td>\n",
       "      <td>http://blog.ethanrosenthal.com/2017/06/20/matr...</td>\n",
       "      <td>2 points</td>\n",
       "      <td>Matrix Factorization in PyTorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>28</td>\n",
       "      <td>vvmisic</td>\n",
       "      <td>2 comments</td>\n",
       "      <td>(arxiv.org)</td>\n",
       "      <td>https://arxiv.org/abs/1705.10883</td>\n",
       "      <td>9 points</td>\n",
       "      <td>Optimization of tree ensembles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>29</td>\n",
       "      <td>genofon</td>\n",
       "      <td>discuss</td>\n",
       "      <td>(techcrunch.com)</td>\n",
       "      <td>https://techcrunch.com/2017/06/16/object-detec...</td>\n",
       "      <td>3 points</td>\n",
       "      <td>Google releases new TensorFlow Object Detectio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index          authors    comments                     domains  \\\n",
       "0        0          meghido     discuss              (roialty.com)    \n",
       "1        1        kokorcsin     discuss               (data36.com)    \n",
       "2        2         lmcinnes     discuss                (github.io)    \n",
       "3        3     freebiesmall     discuss         (freebiesmall.com)    \n",
       "4        4     freebiesmall   1 comment         (freebiesmall.com)    \n",
       "5        5            axelr     discuss                (github.io)    \n",
       "6        6    deeplearningt     discuss    (deeplearningtrack.com)    \n",
       "7        7           Alphax     discuss            (tjpalanca.com)    \n",
       "8        8          marklit     discuss           (marksblogg.com)    \n",
       "9        9         saloni_S   1 comment           (byteacademy.co)    \n",
       "10      10        cavaunpeu     discuss              (willwolf.io)    \n",
       "11      11          Weenkus     discuss          (datawhatnow.com)    \n",
       "12      12       ibobriakov  2 comments             (linkedin.com)    \n",
       "13      13         highraja   1 comment         (paralleldots.com)    \n",
       "14      14      gargisharma     discuss                (sp-bx.com)    \n",
       "15      15          Soapbox     discuss               (data36.com)    \n",
       "16      16        kokorcsin     discuss         (paralleldots.com)    \n",
       "17      17      gargisharma     discuss              (jupyter.org)    \n",
       "18      18           sqadri   1 comment         (paralleldots.com)    \n",
       "19      19      gargisharma     discuss          (blogspot.com.ar)    \n",
       "20      20         enmanuel   1 comment         (freebiesmall.com)    \n",
       "21      21  digambersingh89     discuss   (jonathansacramento.com)    \n",
       "22      22       jmsmistral  3 comments         (paralleldots.com)    \n",
       "23      23      gargisharma     discuss          (datawhatnow.com)    \n",
       "24      24          Weenkus     discuss              (okcupid.com)    \n",
       "25      25          okcdata     discuss            (chris-said.io)    \n",
       "26      26          csaid81  2 comments   (insightdatascience.com)    \n",
       "27      27       mwakanosya     discuss         (paralleldots.com)    \n",
       "28      28      gargisharma     discuss     (autodeskresearch.com)    \n",
       "29      29        Bassviola   1 comment                         NaN   \n",
       "..     ...              ...         ...                         ...   \n",
       "180      0        e_ameisen     discuss   (insightdatascience.com)    \n",
       "181      1           lizeds   1 comment     (elitedatascience.com)    \n",
       "182      2        e_ameisen   1 comment   (insightdatascience.com)    \n",
       "183      3             kate     discuss              (statsbot.co)    \n",
       "184      4   asiaticchamoir     discuss                  (plot.ly)    \n",
       "185      5              pvl     discuss                (kndrck.co)    \n",
       "186      6       ivan_zheng     discuss   (insightdatascience.com)    \n",
       "187      7         saloni_S     discuss           (byteacademy.co)    \n",
       "188      8       feconroses     discuss          (monkeylearn.com)    \n",
       "189      9          mikepqr     discuss              (oreilly.com)    \n",
       "190     10          belokon     discuss              (statsbot.co)    \n",
       "191     11          ashwath     discuss              (scribie.com)    \n",
       "192     12       datactopus     discuss       (datawanderings.com)    \n",
       "193     13            jhoek     discuss         (godatadriven.com)    \n",
       "194     14      HRtechtoday     discuss         (novusviatech.com)    \n",
       "195     15           carolk     discuss               (ayasdi.com)    \n",
       "196     16      dataandsons     discuss          (dataandsons.com)    \n",
       "197     17          tmostak     discuss                 (mapd.com)    \n",
       "198     18          rootkit   1 comment               (medium.com)    \n",
       "199     19        cavaunpeu     discuss              (willwolf.io)    \n",
       "200     20        cavaunpeu     discuss              (willwolf.io)    \n",
       "201     21        kokorcsin     discuss               (data36.com)    \n",
       "202     22          ethikal     discuss               (nvidia.com)    \n",
       "203     23            axelr     discuss                (github.io)    \n",
       "204     24         carlosgg     discuss               (github.com)    \n",
       "205     25      sameermanek     discuss           (techcrunch.com)    \n",
       "206     26           lizeds     discuss     (elitedatascience.com)    \n",
       "207     27            thang     discuss       (ethanrosenthal.com)    \n",
       "208     28          vvmisic  2 comments                (arxiv.org)    \n",
       "209     29          genofon     discuss           (techcrunch.com)    \n",
       "\n",
       "                                                 links     points  \\\n",
       "0    http://roialty.com/why-are-clusters-important-...   2 points   \n",
       "1    https://data36.com/sql-for-data-analysis-tutor...   2 points   \n",
       "2         http://lmcinnes.github.io/subreddit_mapping/  12 points   \n",
       "3    https://www.freebiesmall.com/blog/best-helveti...   2 points   \n",
       "4    https://www.freebiesmall.com/blog/call-to-acti...   5 points   \n",
       "5    http://arogozhnikov.github.io/2017/04/20/machi...  14 points   \n",
       "6    https://www.deeplearningtrack.com/single-post/...  20 points   \n",
       "7    http://www.tjpalanca.com/2017/03/facebook-news...   6 points   \n",
       "8    http://tech.marksblogg.com/billion-nyc-taxi-ri...   8 points   \n",
       "9    http://byteacademy.co/blog/beginner-deep-learn...   2 points   \n",
       "10   http://willwolf.io/2017/05/08/transfer-learnin...   2 points   \n",
       "11   https://datawhatnow.com/simhash-question-dedup...   6 points   \n",
       "12                                       item?id=17958  19 points   \n",
       "13   https://www.linkedin.com/pulse/applying-face-r...   2 points   \n",
       "14   http://blog.paralleldots.com/data-scientist/7-...  15 points   \n",
       "15     https://www.sp-bx.com/getting-grips-blockchain/   6 points   \n",
       "16   https://data36.com/learn-data-analytics-bash-s...   5 points   \n",
       "17   http://blog.paralleldots.com/technology/machin...  18 points   \n",
       "18   http://blog.jupyter.org/2017/04/04/jupyter-not...  20 points   \n",
       "19   http://blog.paralleldots.com/technology/machin...  20 points   \n",
       "20   http://python-apuntes.blogspot.com.ar/2017/04/...   9 points   \n",
       "21   https://www.freebiesmall.com/blog/not-to-miss-...   2 points   \n",
       "22   http://jonathansacramento.com/posts/20170416_c...   7 points   \n",
       "23   http://blog.paralleldots.com/technology/deep-l...  11 points   \n",
       "24          http://datawhatnow.com/feature-importance/   6 points   \n",
       "25   https://tech.okcupid.com/the-pitfalls-of-a-b-t...   7 points   \n",
       "26   http://chris-said.io/2017/05/03/empirical-baye...   2 points   \n",
       "27   https://blog.insightdatascience.com/separating...   3 points   \n",
       "28   http://blog.paralleldots.com/technology/deep-l...   3 points   \n",
       "29   https://www.autodeskresearch.com/publications/...   2 points   \n",
       "..                                                 ...        ...   \n",
       "180  https://blog.insightdatascience.com/the-data-e...   3 points   \n",
       "181     https://elitedatascience.com/beginner-mistakes  13 points   \n",
       "182  https://blog.insightdatascience.com/using-deep...   7 points   \n",
       "183  https://blog.statsbot.co/data-scientist-resume...   9 points   \n",
       "184                     https://plot.ly/products/dash/   7 points   \n",
       "185  https://kndrck.co/indexing-faces-on-instagram....   4 points   \n",
       "186  https://blog.insightdatascience.com/pitcher-pr...   4 points   \n",
       "187   http://byteacademy.co/blog/data-science-podcasts   8 points   \n",
       "188  https://monkeylearn.com/blog/introduction-to-s...   5 points   \n",
       "189  https://www.oreilly.com/learning/probabilistic...   5 points   \n",
       "190  https://blog.statsbot.co/open-source-business-...   9 points   \n",
       "191  https://scribie.com/blog/2017/06/building-cust...   3 points   \n",
       "192  http://datawanderings.com/2017/06/16/ko-by-pro...   4 points   \n",
       "193  https://blog.godatadriven.com/reverse-engineer...   6 points   \n",
       "194           http://novusviatech.com/2017/03/14/1605/   2 points   \n",
       "195  https://www.ayasdi.com/blog/artificial-intelli...   2 points   \n",
       "196                       https://www.dataandsons.com/   3 points   \n",
       "197  https://www.mapd.com/blog/2017/06/18/release-f...   3 points   \n",
       "198  https://medium.com/xtrememl/why-how-to-use-win...   6 points   \n",
       "199  http://willwolf.io/2017/06/19/neurally-embedde...   3 points   \n",
       "200  http://willwolf.io/2017/06/15/random-effects-n...   6 points   \n",
       "201    https://data36.com/optimize-facebook-campaigns/   2 points   \n",
       "202  https://devblogs.nvidia.com/parallelforall/goa...   7 points   \n",
       "203              https://arogozhnikov.github.io/3d_nn/   9 points   \n",
       "204           https://github.com/indrajithi/mgc-django   5 points   \n",
       "205  https://techcrunch.com/2017/06/14/element-ai-a...   6 points   \n",
       "206  https://elitedatascience.com/bias-variance-tra...  17 points   \n",
       "207  http://blog.ethanrosenthal.com/2017/06/20/matr...   2 points   \n",
       "208                   https://arxiv.org/abs/1705.10883   9 points   \n",
       "209  https://techcrunch.com/2017/06/16/object-detec...   3 points   \n",
       "\n",
       "                                                titles  \n",
       "0                     Clustering Social Media Audience  \n",
       "1    SQL for Data Analysis – Tutorial for Beginners...  \n",
       "2        Mapping and Analysing SubReddits Using Python  \n",
       "3    Top 5 Fonts That Can Take The Place of Helveti...  \n",
       "4    Call to Action Button Examples Every UI/UX Des...  \n",
       "5    Machine Learning in Science and Industry [slides]  \n",
       "6    Learn under the hood of Gradient Descent algor...  \n",
       "7    Using topic modeling to find trends in Faceboo...  \n",
       "8    1.1 Billion Taxi Rides with MapD 3.0 & 2 GPU-P...  \n",
       "9                  A Beginner's Guide to Deep Learning  \n",
       "10   Transfer Learning for Flight Delay Prediction ...  \n",
       "11                  SimHash for question deduplication  \n",
       "12   Ask DT: What is the best hardware/GPU for deep...  \n",
       "13   Applying Microsoft Cognitive Emotion Recogniti...  \n",
       "14   7 types of job profiles that make you a Data S...  \n",
       "15                    Getting to grips with Blockchain  \n",
       "16   7 articles to learn basics of Command Line/Bas...  \n",
       "17        Some Lesser Known Machine Learning Libraries  \n",
       "18                                Jupyter Notebook 5.0  \n",
       "19   List of Free Must-Read Books for Machine Learning  \n",
       "20   Python script for create dummies (using \"featu...  \n",
       "21   Not To Miss YouTube Channels For Designers And...  \n",
       "22           Predicting Churn without Machine Learning  \n",
       "23           Some Lesser-Known Deep Learning Libraries  \n",
       "24           Feature importance and why it's important  \n",
       "25      The pitfalls of A/B testing in social networks  \n",
       "26           Empirical Bayes for multiple sample sizes  \n",
       "27   Separating Overlapping Chromosomes with Deep L...  \n",
       "28   Emotion Detection Using Machine Learning - Par...  \n",
       "29                        Same Stats, Different Graphs  \n",
       "..                                                 ...  \n",
       "180             The data engineering ecosystem in 2017  \n",
       "181  9 Mistakes to Avoid When Starting Your Career ...  \n",
       "182  Using Deep Learning to Reconstruct High-Resolu...  \n",
       "183                     Data Scientist Resume Projects  \n",
       "184  Dash by Plotly - Build beautiful web-based int...  \n",
       "185                        Indexing Faces on Instagram  \n",
       "186  Pitcher Prognosis: Using Machine Learning to P...  \n",
       "187  Great list of podcasts if you are interested i...  \n",
       "188         An introduction to Support Vector Machines  \n",
       "189             Probabilistic programming from scratch  \n",
       "190            Open source business intelligence tools  \n",
       "191                Building a Custom Deep Learning Rig  \n",
       "192       Taking Down the NPS Score: KO by Probability  \n",
       "193                  ReveRse engineering BoardGameGeek  \n",
       "194  Improve the Application Process for Candidates...  \n",
       "195  Envisioning the Future of Intelligent Applicat...  \n",
       "196  New Data Exchange for Buying, Selling, and Sha...  \n",
       "197  Density Gradient Maps and Scatterplots in MapD...  \n",
       "198  Why\\How to use Windows Linux Subsytem for end ...  \n",
       "199                           Neurally Embedded Emojis  \n",
       "200  Random Effects Neural Networks in Edward and K...  \n",
       "201  How to Optimize Facebook Campaigns Based on Co...  \n",
       "202          GOAI: Open GPU-Accelerated Data Analytics  \n",
       "203                  Visualizing neural networks in 3d  \n",
       "204                             Music Genre Classifier  \n",
       "205           Element AI raises $102M for AI Incubator  \n",
       "206   WTF is the Bias-Variance Tradeoff? (Infographic)  \n",
       "207                    Matrix Factorization in PyTorch  \n",
       "208                     Optimization of tree ensembles  \n",
       "209  Google releases new TensorFlow Object Detectio...  \n",
       "\n",
       "[210 rows x 7 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, numpy as np\n",
    "\n",
    "def parse_url(url=\"http://www.datatau.com\", data=False):\n",
    "    \n",
    "    response  =  requests.get(url)\n",
    "    links     =  Selector(text=response.text).xpath(\"//td[@class='title']/a/@href\").extract()\n",
    "    titles    =  Selector(text=response.text).xpath(\"//td[@class='title']/a/text()\").extract()\n",
    "    points    =  Selector(text=response.text).xpath(\"//td[@class='subtext']/span/text()\").extract()\n",
    "    domains   =  Selector(text=response.text).xpath(\"//td[@class='title']/span/text()\").extract()\n",
    "    authors   =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'user')]/text()\").extract()\n",
    "    comments  =  Selector(text=response.text).xpath(\"//td[@class='subtext']/a[contains(@href, 'item')]/text()\").extract()\n",
    "\n",
    "    expected_length = 30\n",
    "    \n",
    "    # [np.nan]*(expected_length - len(points)) to the end of the lists, will fill in missing\n",
    "    # values at the end that sometimes don't exist at the ends of the results\n",
    "    scraped = dict(\n",
    "        titles   =  titles[:30], \n",
    "        links    =  links[:30], # :30 because of that damn \"more\" link\n",
    "        points   =  points + [np.nan]*(expected_length - len(points)),\n",
    "        domains  =  domains + [np.nan]*(expected_length - len(domains)),\n",
    "        authors  =  authors + [np.nan]*(expected_length - len(authors)),\n",
    "        comments =  comments + [np.nan]*(expected_length - len(comments))\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(scraped)\n",
    "    \n",
    "    if type(data) != bool:\n",
    "        data = df.append(data)\n",
    "    else:\n",
    "        data = df\n",
    "        \n",
    "    # If there's data append it, if not, it's the first iteration, no need.\n",
    "    # Find more link\n",
    "    more_anchor  =  Selector(text=response.text).xpath(\"//a[text() = 'More']/@href\").extract()\n",
    "    \n",
    "    if len(more_anchor) > 0:\n",
    "        more_url  =  \"http://www.datatau.com%s\" % more_anchor[0]\n",
    "        print \"Fetching %s...\" % more_url\n",
    "        return parse_url(more_url, data=data)\n",
    "    else:\n",
    "        return data.reset_index()\n",
    "       \n",
    "        \n",
    "df = parse_url(\"http://www.datatau.com\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
