{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Data Pipeline Lab\n",
    "\n",
    "_Authors: Richard Harris (CHI)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will be using the famous Titanic survivors dataset. While we will be modeling this data shortly, our first goal will be to create two things:\n",
    "\n",
    "1. Code that transforms our training and test set in the same manner\n",
    "2. Code that takes predictions and stores them to file\n",
    "\n",
    "We have taken this data from the well-known [Kaggle Challenge](https://www.kaggle.com/c/titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# we need to import the template classes to create a class that works like an sklearn class\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../assets/datasets/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../assets/datasets/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function named `age_extractor`. \n",
    "- That takes the dataframe as an input\n",
    "- extracts the age column out of the data frame\n",
    "- Fills missing values with the age '20'\n",
    "- Returns a reshaped Numpy array as such:\n",
    "\n",
    "`series.values.reshape(-1, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_extractor(dataframe):\n",
    "    age = dataframe['Age']\n",
    "    age.fillna(20, inplace=True)\n",
    "    return age.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the \"Survived\" column and assign it to the variable 'y' to use as an outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a LogisticRegression on y _using_ the output of your `age_extractor` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(age_extractor(df), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print out predictions for your model. \n",
    "\n",
    "You should be able to call `age_extractor()` on the test data without too much trouble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression.predict(age_extractor(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate the age_extractor function as a class with the methods transform and fit\n",
    "\n",
    "The following template will help\n",
    "\n",
    "```Python\n",
    "class AgeExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, *args):\n",
    "        # The transform methods needs to returns some type of data that sklearn can understand\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, *args):\n",
    "        # Fit must return self to work within sklearn pipelines\n",
    "        return self\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AgeExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, *args):\n",
    "        age = X['Age']\n",
    "        age.fillna(20, inplace=True)\n",
    "        return age.values.reshape(-1, 1)\n",
    "\n",
    "    def fit(self, X, *args):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test AgeExtractor using the transform method on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22.  ],\n",
       "       [ 38.  ],\n",
       "       [ 26.  ],\n",
       "       [ 35.  ],\n",
       "       [ 35.  ],\n",
       "       [ 20.  ],\n",
       "       [ 54.  ],\n",
       "       [  2.  ],\n",
       "       [ 27.  ],\n",
       "       [ 14.  ],\n",
       "       [  4.  ],\n",
       "       [ 58.  ],\n",
       "       [ 20.  ],\n",
       "       [ 39.  ],\n",
       "       [ 14.  ],\n",
       "       [ 55.  ],\n",
       "       [  2.  ],\n",
       "       [ 20.  ],\n",
       "       [ 31.  ],\n",
       "       [ 20.  ],\n",
       "       [ 35.  ],\n",
       "       [ 34.  ],\n",
       "       [ 15.  ],\n",
       "       [ 28.  ],\n",
       "       [  8.  ],\n",
       "       [ 38.  ],\n",
       "       [ 20.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 40.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 66.  ],\n",
       "       [ 28.  ],\n",
       "       [ 42.  ],\n",
       "       [ 20.  ],\n",
       "       [ 21.  ],\n",
       "       [ 18.  ],\n",
       "       [ 14.  ],\n",
       "       [ 40.  ],\n",
       "       [ 27.  ],\n",
       "       [ 20.  ],\n",
       "       [  3.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 18.  ],\n",
       "       [  7.  ],\n",
       "       [ 21.  ],\n",
       "       [ 49.  ],\n",
       "       [ 29.  ],\n",
       "       [ 65.  ],\n",
       "       [ 20.  ],\n",
       "       [ 21.  ],\n",
       "       [ 28.5 ],\n",
       "       [  5.  ],\n",
       "       [ 11.  ],\n",
       "       [ 22.  ],\n",
       "       [ 38.  ],\n",
       "       [ 45.  ],\n",
       "       [  4.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 29.  ],\n",
       "       [ 19.  ],\n",
       "       [ 17.  ],\n",
       "       [ 26.  ],\n",
       "       [ 32.  ],\n",
       "       [ 16.  ],\n",
       "       [ 21.  ],\n",
       "       [ 26.  ],\n",
       "       [ 32.  ],\n",
       "       [ 25.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [  0.83],\n",
       "       [ 30.  ],\n",
       "       [ 22.  ],\n",
       "       [ 29.  ],\n",
       "       [ 20.  ],\n",
       "       [ 28.  ],\n",
       "       [ 17.  ],\n",
       "       [ 33.  ],\n",
       "       [ 16.  ],\n",
       "       [ 20.  ],\n",
       "       [ 23.  ],\n",
       "       [ 24.  ],\n",
       "       [ 29.  ],\n",
       "       [ 20.  ],\n",
       "       [ 46.  ],\n",
       "       [ 26.  ],\n",
       "       [ 59.  ],\n",
       "       [ 20.  ],\n",
       "       [ 71.  ],\n",
       "       [ 23.  ],\n",
       "       [ 34.  ],\n",
       "       [ 34.  ],\n",
       "       [ 28.  ],\n",
       "       [ 20.  ],\n",
       "       [ 21.  ],\n",
       "       [ 33.  ],\n",
       "       [ 37.  ],\n",
       "       [ 28.  ],\n",
       "       [ 21.  ],\n",
       "       [ 20.  ],\n",
       "       [ 38.  ],\n",
       "       [ 20.  ],\n",
       "       [ 47.  ],\n",
       "       [ 14.5 ],\n",
       "       [ 22.  ],\n",
       "       [ 20.  ],\n",
       "       [ 17.  ],\n",
       "       [ 21.  ],\n",
       "       [ 70.5 ],\n",
       "       [ 29.  ],\n",
       "       [ 24.  ],\n",
       "       [  2.  ],\n",
       "       [ 21.  ],\n",
       "       [ 20.  ],\n",
       "       [ 32.5 ],\n",
       "       [ 32.5 ],\n",
       "       [ 54.  ],\n",
       "       [ 12.  ],\n",
       "       [ 20.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 45.  ],\n",
       "       [ 33.  ],\n",
       "       [ 20.  ],\n",
       "       [ 47.  ],\n",
       "       [ 29.  ],\n",
       "       [ 25.  ],\n",
       "       [ 23.  ],\n",
       "       [ 19.  ],\n",
       "       [ 37.  ],\n",
       "       [ 16.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 22.  ],\n",
       "       [ 24.  ],\n",
       "       [ 19.  ],\n",
       "       [ 18.  ],\n",
       "       [ 19.  ],\n",
       "       [ 27.  ],\n",
       "       [  9.  ],\n",
       "       [ 36.5 ],\n",
       "       [ 42.  ],\n",
       "       [ 51.  ],\n",
       "       [ 22.  ],\n",
       "       [ 55.5 ],\n",
       "       [ 40.5 ],\n",
       "       [ 20.  ],\n",
       "       [ 51.  ],\n",
       "       [ 16.  ],\n",
       "       [ 30.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 44.  ],\n",
       "       [ 40.  ],\n",
       "       [ 26.  ],\n",
       "       [ 17.  ],\n",
       "       [  1.  ],\n",
       "       [  9.  ],\n",
       "       [ 20.  ],\n",
       "       [ 45.  ],\n",
       "       [ 20.  ],\n",
       "       [ 28.  ],\n",
       "       [ 61.  ],\n",
       "       [  4.  ],\n",
       "       [  1.  ],\n",
       "       [ 21.  ],\n",
       "       [ 56.  ],\n",
       "       [ 18.  ],\n",
       "       [ 20.  ],\n",
       "       [ 50.  ],\n",
       "       [ 30.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [  9.  ],\n",
       "       [  1.  ],\n",
       "       [  4.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 45.  ],\n",
       "       [ 40.  ],\n",
       "       [ 36.  ],\n",
       "       [ 32.  ],\n",
       "       [ 19.  ],\n",
       "       [ 19.  ],\n",
       "       [  3.  ],\n",
       "       [ 44.  ],\n",
       "       [ 58.  ],\n",
       "       [ 20.  ],\n",
       "       [ 42.  ],\n",
       "       [ 20.  ],\n",
       "       [ 24.  ],\n",
       "       [ 28.  ],\n",
       "       [ 20.  ],\n",
       "       [ 34.  ],\n",
       "       [ 45.5 ],\n",
       "       [ 18.  ],\n",
       "       [  2.  ],\n",
       "       [ 32.  ],\n",
       "       [ 26.  ],\n",
       "       [ 16.  ],\n",
       "       [ 40.  ],\n",
       "       [ 24.  ],\n",
       "       [ 35.  ],\n",
       "       [ 22.  ],\n",
       "       [ 30.  ],\n",
       "       [ 20.  ],\n",
       "       [ 31.  ],\n",
       "       [ 27.  ],\n",
       "       [ 42.  ],\n",
       "       [ 32.  ],\n",
       "       [ 30.  ],\n",
       "       [ 16.  ],\n",
       "       [ 27.  ],\n",
       "       [ 51.  ],\n",
       "       [ 20.  ],\n",
       "       [ 38.  ],\n",
       "       [ 22.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.5 ],\n",
       "       [ 18.  ],\n",
       "       [ 20.  ],\n",
       "       [ 35.  ],\n",
       "       [ 29.  ],\n",
       "       [ 59.  ],\n",
       "       [  5.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 44.  ],\n",
       "       [  8.  ],\n",
       "       [ 19.  ],\n",
       "       [ 33.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 29.  ],\n",
       "       [ 22.  ],\n",
       "       [ 30.  ],\n",
       "       [ 44.  ],\n",
       "       [ 25.  ],\n",
       "       [ 24.  ],\n",
       "       [ 37.  ],\n",
       "       [ 54.  ],\n",
       "       [ 20.  ],\n",
       "       [ 29.  ],\n",
       "       [ 62.  ],\n",
       "       [ 30.  ],\n",
       "       [ 41.  ],\n",
       "       [ 29.  ],\n",
       "       [ 20.  ],\n",
       "       [ 30.  ],\n",
       "       [ 35.  ],\n",
       "       [ 50.  ],\n",
       "       [ 20.  ],\n",
       "       [  3.  ],\n",
       "       [ 52.  ],\n",
       "       [ 40.  ],\n",
       "       [ 20.  ],\n",
       "       [ 36.  ],\n",
       "       [ 16.  ],\n",
       "       [ 25.  ],\n",
       "       [ 58.  ],\n",
       "       [ 35.  ],\n",
       "       [ 20.  ],\n",
       "       [ 25.  ],\n",
       "       [ 41.  ],\n",
       "       [ 37.  ],\n",
       "       [ 20.  ],\n",
       "       [ 63.  ],\n",
       "       [ 45.  ],\n",
       "       [ 20.  ],\n",
       "       [  7.  ],\n",
       "       [ 35.  ],\n",
       "       [ 65.  ],\n",
       "       [ 28.  ],\n",
       "       [ 16.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 33.  ],\n",
       "       [ 30.  ],\n",
       "       [ 22.  ],\n",
       "       [ 42.  ],\n",
       "       [ 22.  ],\n",
       "       [ 26.  ],\n",
       "       [ 19.  ],\n",
       "       [ 36.  ],\n",
       "       [ 24.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 23.5 ],\n",
       "       [  2.  ],\n",
       "       [ 20.  ],\n",
       "       [ 50.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [  0.92],\n",
       "       [ 20.  ],\n",
       "       [ 17.  ],\n",
       "       [ 30.  ],\n",
       "       [ 30.  ],\n",
       "       [ 24.  ],\n",
       "       [ 18.  ],\n",
       "       [ 26.  ],\n",
       "       [ 28.  ],\n",
       "       [ 43.  ],\n",
       "       [ 26.  ],\n",
       "       [ 24.  ],\n",
       "       [ 54.  ],\n",
       "       [ 31.  ],\n",
       "       [ 40.  ],\n",
       "       [ 22.  ],\n",
       "       [ 27.  ],\n",
       "       [ 30.  ],\n",
       "       [ 22.  ],\n",
       "       [ 20.  ],\n",
       "       [ 36.  ],\n",
       "       [ 61.  ],\n",
       "       [ 36.  ],\n",
       "       [ 31.  ],\n",
       "       [ 16.  ],\n",
       "       [ 20.  ],\n",
       "       [ 45.5 ],\n",
       "       [ 38.  ],\n",
       "       [ 16.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 29.  ],\n",
       "       [ 41.  ],\n",
       "       [ 45.  ],\n",
       "       [ 45.  ],\n",
       "       [  2.  ],\n",
       "       [ 24.  ],\n",
       "       [ 28.  ],\n",
       "       [ 25.  ],\n",
       "       [ 36.  ],\n",
       "       [ 24.  ],\n",
       "       [ 40.  ],\n",
       "       [ 20.  ],\n",
       "       [  3.  ],\n",
       "       [ 42.  ],\n",
       "       [ 23.  ],\n",
       "       [ 20.  ],\n",
       "       [ 15.  ],\n",
       "       [ 25.  ],\n",
       "       [ 20.  ],\n",
       "       [ 28.  ],\n",
       "       [ 22.  ],\n",
       "       [ 38.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 40.  ],\n",
       "       [ 29.  ],\n",
       "       [ 45.  ],\n",
       "       [ 35.  ],\n",
       "       [ 20.  ],\n",
       "       [ 30.  ],\n",
       "       [ 60.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 24.  ],\n",
       "       [ 25.  ],\n",
       "       [ 18.  ],\n",
       "       [ 19.  ],\n",
       "       [ 22.  ],\n",
       "       [  3.  ],\n",
       "       [ 20.  ],\n",
       "       [ 22.  ],\n",
       "       [ 27.  ],\n",
       "       [ 20.  ],\n",
       "       [ 19.  ],\n",
       "       [ 42.  ],\n",
       "       [  1.  ],\n",
       "       [ 32.  ],\n",
       "       [ 35.  ],\n",
       "       [ 20.  ],\n",
       "       [ 18.  ],\n",
       "       [  1.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 17.  ],\n",
       "       [ 36.  ],\n",
       "       [ 21.  ],\n",
       "       [ 28.  ],\n",
       "       [ 23.  ],\n",
       "       [ 24.  ],\n",
       "       [ 22.  ],\n",
       "       [ 31.  ],\n",
       "       [ 46.  ],\n",
       "       [ 23.  ],\n",
       "       [ 28.  ],\n",
       "       [ 39.  ],\n",
       "       [ 26.  ],\n",
       "       [ 21.  ],\n",
       "       [ 28.  ],\n",
       "       [ 20.  ],\n",
       "       [ 34.  ],\n",
       "       [ 51.  ],\n",
       "       [  3.  ],\n",
       "       [ 21.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 33.  ],\n",
       "       [ 20.  ],\n",
       "       [ 44.  ],\n",
       "       [ 20.  ],\n",
       "       [ 34.  ],\n",
       "       [ 18.  ],\n",
       "       [ 30.  ],\n",
       "       [ 10.  ],\n",
       "       [ 20.  ],\n",
       "       [ 21.  ],\n",
       "       [ 29.  ],\n",
       "       [ 28.  ],\n",
       "       [ 18.  ],\n",
       "       [ 20.  ],\n",
       "       [ 28.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 32.  ],\n",
       "       [ 28.  ],\n",
       "       [ 20.  ],\n",
       "       [ 42.  ],\n",
       "       [ 17.  ],\n",
       "       [ 50.  ],\n",
       "       [ 14.  ],\n",
       "       [ 21.  ],\n",
       "       [ 24.  ],\n",
       "       [ 64.  ],\n",
       "       [ 31.  ],\n",
       "       [ 45.  ],\n",
       "       [ 20.  ],\n",
       "       [ 25.  ],\n",
       "       [ 28.  ],\n",
       "       [ 20.  ],\n",
       "       [  4.  ],\n",
       "       [ 13.  ],\n",
       "       [ 34.  ],\n",
       "       [  5.  ],\n",
       "       [ 52.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 30.  ],\n",
       "       [ 49.  ],\n",
       "       [ 20.  ],\n",
       "       [ 29.  ],\n",
       "       [ 65.  ],\n",
       "       [ 20.  ],\n",
       "       [ 50.  ],\n",
       "       [ 20.  ],\n",
       "       [ 48.  ],\n",
       "       [ 34.  ],\n",
       "       [ 47.  ],\n",
       "       [ 48.  ],\n",
       "       [ 20.  ],\n",
       "       [ 38.  ],\n",
       "       [ 20.  ],\n",
       "       [ 56.  ],\n",
       "       [ 20.  ],\n",
       "       [  0.75],\n",
       "       [ 20.  ],\n",
       "       [ 38.  ],\n",
       "       [ 33.  ],\n",
       "       [ 23.  ],\n",
       "       [ 22.  ],\n",
       "       [ 20.  ],\n",
       "       [ 34.  ],\n",
       "       [ 29.  ],\n",
       "       [ 22.  ],\n",
       "       [  2.  ],\n",
       "       [  9.  ],\n",
       "       [ 20.  ],\n",
       "       [ 50.  ],\n",
       "       [ 63.  ],\n",
       "       [ 25.  ],\n",
       "       [ 20.  ],\n",
       "       [ 35.  ],\n",
       "       [ 58.  ],\n",
       "       [ 30.  ],\n",
       "       [  9.  ],\n",
       "       [ 20.  ],\n",
       "       [ 21.  ],\n",
       "       [ 55.  ],\n",
       "       [ 71.  ],\n",
       "       [ 21.  ],\n",
       "       [ 20.  ],\n",
       "       [ 54.  ],\n",
       "       [ 20.  ],\n",
       "       [ 25.  ],\n",
       "       [ 24.  ],\n",
       "       [ 17.  ],\n",
       "       [ 21.  ],\n",
       "       [ 20.  ],\n",
       "       [ 37.  ],\n",
       "       [ 16.  ],\n",
       "       [ 18.  ],\n",
       "       [ 33.  ],\n",
       "       [ 20.  ],\n",
       "       [ 28.  ],\n",
       "       [ 26.  ],\n",
       "       [ 29.  ],\n",
       "       [ 20.  ],\n",
       "       [ 36.  ],\n",
       "       [ 54.  ],\n",
       "       [ 24.  ],\n",
       "       [ 47.  ],\n",
       "       [ 34.  ],\n",
       "       [ 20.  ],\n",
       "       [ 36.  ],\n",
       "       [ 32.  ],\n",
       "       [ 30.  ],\n",
       "       [ 22.  ],\n",
       "       [ 20.  ],\n",
       "       [ 44.  ],\n",
       "       [ 20.  ],\n",
       "       [ 40.5 ],\n",
       "       [ 50.  ],\n",
       "       [ 20.  ],\n",
       "       [ 39.  ],\n",
       "       [ 23.  ],\n",
       "       [  2.  ],\n",
       "       [ 20.  ],\n",
       "       [ 17.  ],\n",
       "       [ 20.  ],\n",
       "       [ 30.  ],\n",
       "       [  7.  ],\n",
       "       [ 45.  ],\n",
       "       [ 30.  ],\n",
       "       [ 20.  ],\n",
       "       [ 22.  ],\n",
       "       [ 36.  ],\n",
       "       [  9.  ],\n",
       "       [ 11.  ],\n",
       "       [ 32.  ],\n",
       "       [ 50.  ],\n",
       "       [ 64.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 33.  ],\n",
       "       [  8.  ],\n",
       "       [ 17.  ],\n",
       "       [ 27.  ],\n",
       "       [ 20.  ],\n",
       "       [ 22.  ],\n",
       "       [ 22.  ],\n",
       "       [ 62.  ],\n",
       "       [ 48.  ],\n",
       "       [ 20.  ],\n",
       "       [ 39.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 40.  ],\n",
       "       [ 28.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 24.  ],\n",
       "       [ 19.  ],\n",
       "       [ 29.  ],\n",
       "       [ 20.  ],\n",
       "       [ 32.  ],\n",
       "       [ 62.  ],\n",
       "       [ 53.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 16.  ],\n",
       "       [ 19.  ],\n",
       "       [ 34.  ],\n",
       "       [ 39.  ],\n",
       "       [ 20.  ],\n",
       "       [ 32.  ],\n",
       "       [ 25.  ],\n",
       "       [ 39.  ],\n",
       "       [ 54.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 18.  ],\n",
       "       [ 47.  ],\n",
       "       [ 60.  ],\n",
       "       [ 22.  ],\n",
       "       [ 20.  ],\n",
       "       [ 35.  ],\n",
       "       [ 52.  ],\n",
       "       [ 47.  ],\n",
       "       [ 20.  ],\n",
       "       [ 37.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 49.  ],\n",
       "       [ 20.  ],\n",
       "       [ 49.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 44.  ],\n",
       "       [ 35.  ],\n",
       "       [ 36.  ],\n",
       "       [ 30.  ],\n",
       "       [ 27.  ],\n",
       "       [ 22.  ],\n",
       "       [ 40.  ],\n",
       "       [ 39.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 35.  ],\n",
       "       [ 24.  ],\n",
       "       [ 34.  ],\n",
       "       [ 26.  ],\n",
       "       [  4.  ],\n",
       "       [ 26.  ],\n",
       "       [ 27.  ],\n",
       "       [ 42.  ],\n",
       "       [ 20.  ],\n",
       "       [ 21.  ],\n",
       "       [ 21.  ],\n",
       "       [ 61.  ],\n",
       "       [ 57.  ],\n",
       "       [ 21.  ],\n",
       "       [ 26.  ],\n",
       "       [ 20.  ],\n",
       "       [ 80.  ],\n",
       "       [ 51.  ],\n",
       "       [ 32.  ],\n",
       "       [ 20.  ],\n",
       "       [  9.  ],\n",
       "       [ 28.  ],\n",
       "       [ 32.  ],\n",
       "       [ 31.  ],\n",
       "       [ 41.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 24.  ],\n",
       "       [  2.  ],\n",
       "       [ 20.  ],\n",
       "       [  0.75],\n",
       "       [ 48.  ],\n",
       "       [ 19.  ],\n",
       "       [ 56.  ],\n",
       "       [ 20.  ],\n",
       "       [ 23.  ],\n",
       "       [ 20.  ],\n",
       "       [ 18.  ],\n",
       "       [ 21.  ],\n",
       "       [ 20.  ],\n",
       "       [ 18.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 32.  ],\n",
       "       [ 23.  ],\n",
       "       [ 58.  ],\n",
       "       [ 50.  ],\n",
       "       [ 40.  ],\n",
       "       [ 47.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 32.  ],\n",
       "       [ 25.  ],\n",
       "       [ 20.  ],\n",
       "       [ 43.  ],\n",
       "       [ 20.  ],\n",
       "       [ 40.  ],\n",
       "       [ 31.  ],\n",
       "       [ 70.  ],\n",
       "       [ 31.  ],\n",
       "       [ 20.  ],\n",
       "       [ 18.  ],\n",
       "       [ 24.5 ],\n",
       "       [ 18.  ],\n",
       "       [ 43.  ],\n",
       "       [ 36.  ],\n",
       "       [ 20.  ],\n",
       "       [ 27.  ],\n",
       "       [ 20.  ],\n",
       "       [ 14.  ],\n",
       "       [ 60.  ],\n",
       "       [ 25.  ],\n",
       "       [ 14.  ],\n",
       "       [ 19.  ],\n",
       "       [ 18.  ],\n",
       "       [ 15.  ],\n",
       "       [ 31.  ],\n",
       "       [  4.  ],\n",
       "       [ 20.  ],\n",
       "       [ 25.  ],\n",
       "       [ 60.  ],\n",
       "       [ 52.  ],\n",
       "       [ 44.  ],\n",
       "       [ 20.  ],\n",
       "       [ 49.  ],\n",
       "       [ 42.  ],\n",
       "       [ 18.  ],\n",
       "       [ 35.  ],\n",
       "       [ 18.  ],\n",
       "       [ 25.  ],\n",
       "       [ 26.  ],\n",
       "       [ 39.  ],\n",
       "       [ 45.  ],\n",
       "       [ 42.  ],\n",
       "       [ 22.  ],\n",
       "       [ 20.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 48.  ],\n",
       "       [ 29.  ],\n",
       "       [ 52.  ],\n",
       "       [ 19.  ],\n",
       "       [ 38.  ],\n",
       "       [ 27.  ],\n",
       "       [ 20.  ],\n",
       "       [ 33.  ],\n",
       "       [  6.  ],\n",
       "       [ 17.  ],\n",
       "       [ 34.  ],\n",
       "       [ 50.  ],\n",
       "       [ 27.  ],\n",
       "       [ 20.  ],\n",
       "       [ 30.  ],\n",
       "       [ 20.  ],\n",
       "       [ 25.  ],\n",
       "       [ 25.  ],\n",
       "       [ 29.  ],\n",
       "       [ 11.  ],\n",
       "       [ 20.  ],\n",
       "       [ 23.  ],\n",
       "       [ 23.  ],\n",
       "       [ 28.5 ],\n",
       "       [ 48.  ],\n",
       "       [ 35.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 36.  ],\n",
       "       [ 21.  ],\n",
       "       [ 24.  ],\n",
       "       [ 31.  ],\n",
       "       [ 70.  ],\n",
       "       [ 16.  ],\n",
       "       [ 30.  ],\n",
       "       [ 19.  ],\n",
       "       [ 31.  ],\n",
       "       [  4.  ],\n",
       "       [  6.  ],\n",
       "       [ 33.  ],\n",
       "       [ 23.  ],\n",
       "       [ 48.  ],\n",
       "       [  0.67],\n",
       "       [ 28.  ],\n",
       "       [ 18.  ],\n",
       "       [ 34.  ],\n",
       "       [ 33.  ],\n",
       "       [ 20.  ],\n",
       "       [ 41.  ],\n",
       "       [ 20.  ],\n",
       "       [ 36.  ],\n",
       "       [ 16.  ],\n",
       "       [ 51.  ],\n",
       "       [ 20.  ],\n",
       "       [ 30.5 ],\n",
       "       [ 20.  ],\n",
       "       [ 32.  ],\n",
       "       [ 24.  ],\n",
       "       [ 48.  ],\n",
       "       [ 57.  ],\n",
       "       [ 20.  ],\n",
       "       [ 54.  ],\n",
       "       [ 18.  ],\n",
       "       [ 20.  ],\n",
       "       [  5.  ],\n",
       "       [ 20.  ],\n",
       "       [ 43.  ],\n",
       "       [ 13.  ],\n",
       "       [ 17.  ],\n",
       "       [ 29.  ],\n",
       "       [ 20.  ],\n",
       "       [ 25.  ],\n",
       "       [ 25.  ],\n",
       "       [ 18.  ],\n",
       "       [  8.  ],\n",
       "       [  1.  ],\n",
       "       [ 46.  ],\n",
       "       [ 20.  ],\n",
       "       [ 16.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 25.  ],\n",
       "       [ 39.  ],\n",
       "       [ 49.  ],\n",
       "       [ 31.  ],\n",
       "       [ 30.  ],\n",
       "       [ 30.  ],\n",
       "       [ 34.  ],\n",
       "       [ 31.  ],\n",
       "       [ 11.  ],\n",
       "       [  0.42],\n",
       "       [ 27.  ],\n",
       "       [ 31.  ],\n",
       "       [ 39.  ],\n",
       "       [ 18.  ],\n",
       "       [ 39.  ],\n",
       "       [ 33.  ],\n",
       "       [ 26.  ],\n",
       "       [ 39.  ],\n",
       "       [ 35.  ],\n",
       "       [  6.  ],\n",
       "       [ 30.5 ],\n",
       "       [ 20.  ],\n",
       "       [ 23.  ],\n",
       "       [ 31.  ],\n",
       "       [ 43.  ],\n",
       "       [ 10.  ],\n",
       "       [ 52.  ],\n",
       "       [ 27.  ],\n",
       "       [ 38.  ],\n",
       "       [ 27.  ],\n",
       "       [  2.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [  1.  ],\n",
       "       [ 20.  ],\n",
       "       [ 62.  ],\n",
       "       [ 15.  ],\n",
       "       [  0.83],\n",
       "       [ 20.  ],\n",
       "       [ 23.  ],\n",
       "       [ 18.  ],\n",
       "       [ 39.  ],\n",
       "       [ 21.  ],\n",
       "       [ 20.  ],\n",
       "       [ 32.  ],\n",
       "       [ 20.  ],\n",
       "       [ 20.  ],\n",
       "       [ 16.  ],\n",
       "       [ 30.  ],\n",
       "       [ 34.5 ],\n",
       "       [ 17.  ],\n",
       "       [ 42.  ],\n",
       "       [ 20.  ],\n",
       "       [ 35.  ],\n",
       "       [ 28.  ],\n",
       "       [ 20.  ],\n",
       "       [  4.  ],\n",
       "       [ 74.  ],\n",
       "       [  9.  ],\n",
       "       [ 16.  ],\n",
       "       [ 44.  ],\n",
       "       [ 18.  ],\n",
       "       [ 45.  ],\n",
       "       [ 51.  ],\n",
       "       [ 24.  ],\n",
       "       [ 20.  ],\n",
       "       [ 41.  ],\n",
       "       [ 21.  ],\n",
       "       [ 48.  ],\n",
       "       [ 20.  ],\n",
       "       [ 24.  ],\n",
       "       [ 42.  ],\n",
       "       [ 27.  ],\n",
       "       [ 31.  ],\n",
       "       [ 20.  ],\n",
       "       [  4.  ],\n",
       "       [ 26.  ],\n",
       "       [ 47.  ],\n",
       "       [ 33.  ],\n",
       "       [ 47.  ],\n",
       "       [ 28.  ],\n",
       "       [ 15.  ],\n",
       "       [ 20.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 56.  ],\n",
       "       [ 25.  ],\n",
       "       [ 33.  ],\n",
       "       [ 22.  ],\n",
       "       [ 28.  ],\n",
       "       [ 25.  ],\n",
       "       [ 39.  ],\n",
       "       [ 27.  ],\n",
       "       [ 19.  ],\n",
       "       [ 20.  ],\n",
       "       [ 26.  ],\n",
       "       [ 32.  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = AgeExtractor()\n",
    "age.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refit logistic regression using AgeExtractor to transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(age.transform(df), y)\n",
    "logistic_regression.predict(age.transform(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function named `output_predictions` that takes an array of predictions and a name of a csv file. \n",
    "\n",
    "This function should take your predictions, imports it into a Pandas series, names the column 'Predictions', and saves them to a CSV file named as appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_predictions(predicts, filename):\n",
    "    csv_series = pd.Series(predicts, name='Predictions')\n",
    "    csv_series.to_csv(filename, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run output_predictions on the prediction from logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_predictions(logistic_regression.predict(age_extractor(test)), 'test_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to try out what happens when we have two columns we want to model. \n",
    "\n",
    "### Write a function named `gender_extractor`. \n",
    "\n",
    "That takes in the dataframe, extracts the gender column, turns it into a dummy variable, fills any missing values with `0`, and returns the reshaped array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gender_extractor(dataframe):\n",
    "    sex = dataframe['Sex']\n",
    "    sex = sex.apply(lambda x: 1 if x=='male' else 0)\n",
    "    sex.fillna(0, inplace=True)\n",
    "    return sex.values.reshape(-1, 1)\n",
    "\n",
    "gender_extractor(df)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recreate the age_extractor function as a class with the methods transform and fit\n",
    "\n",
    "The following template will help\n",
    "\n",
    "```Python\n",
    "class GenderExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, *args):\n",
    "        # The transform methods needs to returns some type of data that sklearn can understand\n",
    "        return X\n",
    "\n",
    "    def fit(self, X, *args):\n",
    "        # Fit must return self to work within sklearn pipelines\n",
    "        return self\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GenderExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X, *args):\n",
    "        sex = X['Sex']\n",
    "        sex = sex.apply(lambda x: 1 if x=='male' else 0)\n",
    "        sex.fillna(0, inplace=True)\n",
    "        return sex.values.reshape(-1, 1)\n",
    "\n",
    "    def fit(self, X, *args):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test GenderExtractor using the transform method on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender = GenderExtractor()\n",
    "gender.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to join these two columns together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a function named `join_arrays()` that takes in a tuple of arrays and returns one array joined together\n",
    "\n",
    "This would use the concatenate feature of Numpy like this:\n",
    "\n",
    "`new_array = np.concatenate((array1, array2), axis=1)`\n",
    "\n",
    "[np.concatenate](https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22.,   1.],\n",
       "       [ 38.,   0.],\n",
       "       [ 26.,   0.],\n",
       "       ..., \n",
       "       [ 20.,   0.],\n",
       "       [ 26.,   1.],\n",
       "       [ 32.,   1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def join_arrays(arrays):\n",
    "    return np.concatenate(arrays, axis=1)\n",
    "\n",
    "join_arrays((age_extractor(df), gender_extractor(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can achieve the same effect using sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the FeatureUnion class from sklearn to take instances of AgeExtractor and GenderExtractor and combine their output into one dataframe\n",
    "- You might create a variable called combine and store the FeatureUnion instance in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine = FeatureUnion([('age', age), ('gender', gender)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the FeatureUnion instance using .transform() on our data\n",
    "- Make sure that you get a 2 dimensional numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 22.,   1.],\n",
       "       [ 38.,   0.],\n",
       "       [ 26.,   0.],\n",
       "       ..., \n",
       "       [ 20.,   0.],\n",
       "       [ 26.,   1.],\n",
       "       [ 32.,   1.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want one function that joins all of these features together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sklearn pipeline called lr_pipe. \n",
    "The pipeline should:\n",
    "1. Have a feature union step\n",
    "    - The FeatureUnion instance should union the AgeExtractor class and GenderExtractor class\n",
    "    - This gives us a 2 dimensional numpy array\n",
    "2. Run run logistic_regression\n",
    "\n",
    "We will be able to run .fit() and .predict() on the entire pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('age', age), \n",
    "        ('gender', gender)\n",
    "    ])),\n",
    "    ('logreg', logistic_regression)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit your logistic regression using lr_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('age', AgeExtractor()), ('gender', GenderExtractor())],\n",
       "       transformer_weights=None)), ('logreg', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.fit(df, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed the data from `test.csv` through lr_pipe.predict() and predict values using your newly fit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed those predictions into the `output_predictions()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_predictions(lr_pipe.predict(test), 'new_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "\n",
    "1. Modify your code further. Iterate over some additional features, decide how you want to transform those features. Create new functions to reproducibly transform individual columns. Add that to `preprocessor()`. Refit the logistic model required.\n",
    "2. Attempt this with a kNN model. You will need to standardize your features. Just like LogisticRegression we can fit our StandardScaler to one set of data and transform it according to that standard, like this:\n",
    "\n",
    "```\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard = StandardScaler()\n",
    "standard.fit(train_data['column'])\n",
    "\n",
    "standardized_train_data = standard.transform(train_data['column'])\n",
    "standardized_test_data = standard.transform(test_data['column'])\n",
    "```\n",
    "\n",
    "Your deliverables are:\n",
    "\n",
    "1. At least one additional column added to `preprocessor()`\n",
    "2. A `preprocessor()` function that standardizes at least one input using `StandardScaler` as written above \n",
    "3. Apply the standardized feature to a kNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
